{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group 16 Project Propososal code",
      "provenance": [],
      "mount_file_id": "1hIPwj_nO8yLhyzUsWm8QmyekCNenILh-",
      "authorship_tag": "ABX9TyNGt0snecmieWa8J0fTvWeG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelUOFC/DeepLearningProposal/blob/main/Group_16_Project_Propososal_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9XXO06cQufp"
      },
      "source": [
        "\n",
        "import os\n",
        "from shutil import copy2\n",
        "import csv\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flnn4lLZ39nq"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31wGaxg4lPcj"
      },
      "source": [
        "data_root=(\"/content/drive/MyDrive/custom_image_classification-master/Dataset\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiMO1x3Az4Er"
      },
      "source": [
        "IMAGE_SHAPE = (224, 224) # (height, width) in no. of pixels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgr3C0sc0qFj"
      },
      "source": [
        "TRAINING_DATA_DIR = str(data_root) # set the Training data directory"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxAJrcQb1eUP"
      },
      "source": [
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20) # to rescale the image and split data into training and validation"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hqf1hzU2YNF",
        "outputId": "9a7c27c8-d78f-48b9-de1e-0f3453b955ef"
      },
      "source": [
        "# create train_generator and valid_generator\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset=\"validation\",\n",
        "shuffle=True,\n",
        "target_size=IMAGE_SHAPE\n",
        ")\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset=\"training\",\n",
        "shuffle=True,\n",
        "target_size=IMAGE_SHAPE)\n",
        "print(\"The first line is for validation data and the second line is for training data.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1195 images belonging to 4 classes.\n",
            "Found 4788 images belonging to 4 classes.\n",
            "The first line is for validation data and the second line is for training data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvf4OpN4-Qyt",
        "outputId": "6dfc0e8d-4f46-4a23-f182-1a5619f43f30"
      },
      "source": [
        "# Visualizing the data: images and labels in train_generator\n",
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 224, 224, 3), (32, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g51dN727EO6R"
      },
      "source": [
        "The default batch size is 32, as it is considered appropriate in most of the cases. (32, 244, 244, 3) means in one batch of images consist of 32 images and 244, 244 is height and width of images and 3 is RGB three colour channels.\n",
        "\n",
        "label_batch shape is (32, 4) means there are 32 labels and 4 because the labels are in one hot encoded format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lz-u4QR-9iL",
        "outputId": "1aa6ca31-0344-4114-8712-a4675a865d17"
      },
      "source": [
        "# letâ€™s see which indices represents which labels\n",
        "print (train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Attire': 0, 'Decorationandsignage': 1, 'Food': 2, 'Misc': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uzJgiIUEKVT",
        "outputId": "cda76977-0e23-4a55-e9f5-95a2e45cc50d"
      },
      "source": [
        "# Writing all labels into a text file\n",
        "(sorted(train_generator.class_indices.keys()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Attire', 'Decorationandsignage', 'Food', 'Misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK0PTK30UzEJ",
        "outputId": "0b4fe143-8397-41d2-a6a8-74a0f3fdcb36"
      },
      "source": [
        "# Create a classification model: A Transfer Learning using TensorFlow hub to Load a pre-trained model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", \n",
        "                 output_shape=[1280],\n",
        "                 trainable=False),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "model.build([None, 224, 224, 3])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 5124      \n",
            "=================================================================\n",
            "Total params: 2,263,108\n",
            "Trainable params: 5,124\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUu58elg4-Fo"
      },
      "source": [
        "# Before training the model we need to compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
        "model.compile(\n",
        " optimizer=optimizer,\n",
        " loss='categorical_crossentropy',\n",
        " metrics=['acc'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T98BSBDp5mMx",
        "outputId": "7b0e52c5-0133-4f13-fc72-d44736f1d859"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
        "val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)\n",
        "\n",
        "hist = model.fit(\n",
        "    train_generator, \n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=val_steps_per_epoch).history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "150/150 [==============================] - 1411s 9s/step - loss: 1.4779 - acc: 0.4325 - val_loss: 0.8471 - val_acc: 0.6510\n",
            "Epoch 2/100\n",
            "150/150 [==============================] - 205s 1s/step - loss: 0.9570 - acc: 0.6353 - val_loss: 0.7907 - val_acc: 0.6954\n",
            "Epoch 3/100\n",
            "150/150 [==============================] - 204s 1s/step - loss: 0.8441 - acc: 0.6706 - val_loss: 0.7577 - val_acc: 0.6971\n",
            "Epoch 4/100\n",
            "150/150 [==============================] - 202s 1s/step - loss: 0.7905 - acc: 0.6955 - val_loss: 0.7719 - val_acc: 0.6996\n",
            "Epoch 5/100\n",
            "150/150 [==============================] - 203s 1s/step - loss: 0.7779 - acc: 0.7052 - val_loss: 0.7607 - val_acc: 0.6979\n",
            "Epoch 6/100\n",
            "150/150 [==============================] - 202s 1s/step - loss: 0.7601 - acc: 0.7114 - val_loss: 0.7300 - val_acc: 0.7105\n",
            "Epoch 7/100\n",
            "150/150 [==============================] - 205s 1s/step - loss: 0.7103 - acc: 0.7275 - val_loss: 0.7436 - val_acc: 0.7054\n",
            "Epoch 8/100\n",
            "150/150 [==============================] - 203s 1s/step - loss: 0.7462 - acc: 0.7104 - val_loss: 0.7283 - val_acc: 0.7046\n",
            "Epoch 9/100\n",
            "150/150 [==============================] - 202s 1s/step - loss: 0.6964 - acc: 0.7350 - val_loss: 0.7451 - val_acc: 0.7038\n",
            "Epoch 10/100\n",
            "150/150 [==============================] - 203s 1s/step - loss: 0.6969 - acc: 0.7336 - val_loss: 0.7511 - val_acc: 0.7071\n",
            "Epoch 11/100\n",
            "150/150 [==============================] - 205s 1s/step - loss: 0.7005 - acc: 0.7298 - val_loss: 0.7304 - val_acc: 0.7113\n",
            "Epoch 12/100\n",
            "122/150 [=======================>......] - ETA: 30s - loss: 0.6930 - acc: 0.7263"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrp0MDIV7iuh"
      },
      "source": [
        "# Let see how good is our model\n",
        "\n",
        "final_loss, final_accuracy = model.evaluate(valid_generator, steps = val_steps_per_epoch)\n",
        "print(\"Final loss: {:.2f}\".format(final_loss))\n",
        "print(\"Final accuracy: {:.2f}%\".format(final_accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th9Jq4757kTv"
      },
      "source": [
        "# Plotting some graphs : these plots will help us know how well the training has been done.\n",
        "# orange for validation, and blue is for training accuracy \n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,50])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"acc\"])\n",
        "plt.plot(hist[\"val_acc\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9056-PP7tkc"
      },
      "source": [
        "# save trained model, and checking the performance of the model\n",
        "\n",
        "val_image_batch, val_label_batch = next(iter(valid_generator))\n",
        "true_label_ids = np.argmax(val_label_batch, axis=-1)\n",
        "print(\"Validation batch shape:\", val_image_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7PWdmLA70Py"
      },
      "source": [
        "dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n",
        "dataset_labels = np.array([key.title() for key, value in dataset_labels])\n",
        "print(dataset_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtSjCPab8IS1"
      },
      "source": [
        "tf_model_predictions = model.predict(val_image_batch)\n",
        "print(\"Prediction results shape:\", tf_model_predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1QN6FXC8Mne"
      },
      "source": [
        "predicted_ids = np.argmax(tf_model_predictions, axis=-1)\n",
        "predicted_labels = dataset_labels[predicted_ids]\n",
        "print(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-N7rHQk8RDO"
      },
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range((len(predicted_labels)-2)):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(val_image_batch[n])\n",
        "  color = \"green\" if predicted_ids[n] == true_label_ids[n] else \"red\"\n",
        "  plt.title(predicted_labels[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}